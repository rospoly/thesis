\Mahmoudd{\section{Revision Letter}	
We thank the reviewers for the detailed and useful feedback on our submission. First, we will detail the main changes we made. Below, we provide responses to your specific questions. 
\subsection{Changes}
We have improved our paper while considering all the minor comments. Particularly, \autoref{fig:overview} is updated and the Remark \ref{rem:eps_Q} is added. Other changes are minor and are highlighted within the body of the paper. We also plan to distribute our tool once the double blinded review phase is passed.
\subsection{Responses}
Here, we provide answer to the main inquiries posed by the reviewers. These points will be added later into the main body of the final version of our paper.\\
\textbf{Significance of memory savings reported in the paper} (Reviewer 1)\\
Explicit MPC is a class of controllers which is mainly appropriate for implementation over processors with limited computational power as it omits the need for massive online optimizations. This speed up in execution comes however with relatively high memory demand due to high number of PWA mappings that must be saved over the memory. Typical memory of these processors is in the order of tens of kilobytes (e.g. $32$ KB) and hence $21$ KB is considered as a significant saving.\\
\textbf{Do memory savings in our approach come with a run-time cost?} (Reviewer 1)\\
No. It should be noticed that savings are not affecting the run-time as synthesizing of the controller and the corresponding mixed precision computations are all performed offline. The output of our analysis is an implementation in mixed precision arithmetic that checks which polyhedral region the current state belongs to and computes the corresponding affine mapping. This computation is fast. See below for further discussion.\\
\textbf{Do achieved savings correspond also to actual implementation?} (Reviewers 1 $\&$ 4)\\
MATLAB and Daisy are solely used for offline computations. The output of our algorithm contains (almost) all the information required for implementation of the verified controller over embedded systems. Therefore, the same savings can be expected when the controller is implemented on an actual embedded system.\\
\textbf{Taking uncertainties other than quantization into account} (Reviewer 1)\\
Our formulation is general enough to take the effect of measurement/process noise into account. More specifically, $\Delta$ in $\mathcal{W}_{\Delta}$ can in general give upper-bound over the sum of uncertainties with different sources. However, this is not subject of study of the current paper.\\
\textbf{Complexity of the proposed approach} (Reviewer 2)\\
In \cite{Alessio2009} it is shown that the upper bound over the number of regions $P$ is $2^q$, where $q$ denotes the total number of constraints in \autoref{eq:RMPC_prob}. In theory one cannot find an upper bound for the maximum number of hyperplanes enclosing a region. To compute the incorrect region selection error, assuming that each partition at most has $\bar n_f$ faces, in the worst case $i\times\bar n_f\times 2^q$ affine computations would be enough, where $i$ denotes the number of times that RMPC design is repeated for updated $\Delta$s. In our experiments, computation of incorrect region selection takes only a few minutes for our largest tested benchmarks. %\underline{\textbf{Rocco: What about complexity of Daisy's computations in terms of number of regions $P$ and $n$?}} 		
\\
The complexity of precision tuning is linear with respect to the number of regions and hyperplanes. So, $P+\bar n_f\times P$ is an upper bound for the number of problems we need to encode in Daisy.
In each encoding, the uniform-precision detection takes linear number of steps before convergence. It starts from 1-bit and increases the precision one by one until the first valid configuration. The complexity of mixed-precision tuning, with delta-debugging, is $n\times log(n)$ in average, and bounded by $n^2$ in the worst case, with n number of variables.\\
\textbf{Extension of the proposed method into the nonlinear dynamical systems} (Reviwer 2)\\
It should be noticed that EMPC is a class of controllers specifically proposed for linear time invariant (LTI) systems. To cover nonlinear systems, one approach is to linearize them around an appropriately selected equilibrium point of the system and to model the differences as a bounded disturbance as in \autoref{eq:RMPC_prob}. Taking the upper bound over nonlinearities into account will result in enlarging $\Delta$ which characterizes $\mathcal{W}_{\Delta}$. For reasonable values of $\Delta$, in principle RMPC design should work successfully. Further, it should be noticed that the rest of analysis (over MATLAB and Daisy) do not rely on the LTI property of the under study system and could be adjusted for other families of controllers. However, such analysis are beyond the scope of this paper as (perturbed) LTI systems are considered as an important class of dynamical systems.\\ 
\textbf{Releasing the developed package} (Reviewers 3 $\&$ 4)\\
We definitely plan to distribute our package once the double blinded review phase is passed.\\ 
\textbf{Reason for the special format of solution to \autoref{eq:RMPC_prob} as polyhedral decomposition} (Reviewer 3)\\
We use the results in \cite{delaPea:2005}; since this is not among this paper's contributions, we do not go beyond giving a general outline of these results. In particular, we omitted the proof from \cite{delaPea:2005}.
\\
\textbf{Execution time for EMPCs} (Reviewer 4)\\
The total time to evaluate the PWA function for a given $x_k$ in \autoref{eq:affine_map} consists of two steps:
\begin{itemize}
\item Selecting the region $\mathcal R_i$ such that $x_k\in \mathcal R_i$.
\item To evaluate the corresponding affine map $F_i x_k +G_i$. 
\end{itemize}
Evaluating the affine map is straightforward and requires less computational effort compared to the region selection step. Direct implementation of region selection (\autoref{lst:caseof}) is simple, but inefficient. More efficiency can be achieved by leveraging binary search tree structures (e.g. \cite{Mnnigmann:2011}). In general, explicit MPC is well-known for its high-speed implementation over embedded systems with low computational power. \cite{Johansen:2007} shows that explicit MPCs with hundreds of regions can be implemented on application specific integrated circuit (ASIC) with about $20000$ gates, leading to computation times in the order of $1\mu s$. In \cite{Bemporad:2006}, it is shown that for typical problems evaluating the explicit MPC takes significantly shorter time in comparison to solving on-line QP. \\
\textbf{Termination of the algorithm for robust EMPC design (Reviewer 4)}\\
From a theoretical point of view, the numerical error does not necessarily converge as each new designed controller may differ from the previous ones. Therefore, it is not easy to give an upper bound over the number of times that the robust MPC design needs to be repeated. However, one can use results on continuity of $argmin$ function in 
\begin{align*}
\label{eq:argmin}
&u_0(x_0,\Delta),\cdots,u_{N-1}(x_0,\Delta)=\\
&argmin \max_{w_0,\cdots,w_{N-1}} \sum_{i=0}^{N-1}(x_i^TQx_i+u_i^TRu_i) + x_N^TQ_Fx_N\nonumber\\
&\text{s.t.} \quad x_{i+1}=Ax_i+Bu_i + E w_i, \quad\forall i\in\{0,1,\cdots,N-1\}\nonumber\\
%\quad &u_i=\mu x_i+v_i, \quad\forall i\in\{0,1,\cdots,N-1\}\nonumber\\
&u_i\in\mathcal{U},x_i\in\mathcal{X},\quad \forall w_i\in\mathcal{W}_{\Delta},\,\,\forall i\in\{0,1,\cdots,N\},
\end{align*}
 assuming its unique solution to every $\Delta$ and compute the Lipschitz constant for it over variations of $\Delta$. The computed Lipschitz constant will be only dependent on the dynamics of the system depicted in \autoref{eq:DSS} and hence can be used to evaluate the maximum error over incorrect region selection. This Lipschitz constant can be quite large, leading into a very conservative bound on maximum number of iterations before convergence. However, from an experimental point of view, using a reasonable $\varepsilon_{SAFE}$, our observations show that convergence always happened after only a few iterations.
}
