%!TEX root = main.tex
\section{Error Analysis}
\label{sec:Error_Analysis}

In this section, we present our error analysis assuming that a fixed word length $p$ is given.
Then in the next section, we explain our optimization algorithm which determines suitable word
lengths for different variables fully automatically. % in~\autoref{sec:Controller_Synthesis}.
%
% For simplicity of notation, we assume in this section a uniform word length $p$,
% but our algorithm (and implementation) is applied to mixed-precision to reduce the memory usage.

Consider the controller obtained from explicit MPC according to Theorem~\ref{thm:EMPC}.
Define the affine control functions associated with each polyhedral region $\mathcal R_i$, $i\in\{1,2,\ldots, P\}$, as
$$v_{i}:\mathcal R_i\rightarrow \mathcal U \quad \text{ with } \quad v_{i}(x) := F_i x + G_i.$$
Implementation of the controller can be affected by two main sources of
error:
%which an error analysis has to capture \cite{imperialrmpc}:
\begin{itemize}
  \item[(i)] \emph{incorrect region selection}:
   instead of a correct affine function $v_{i}$, the implementation may choose an incorrect affine function $v_{j}$. This can happen either
    due to an analog-to-digital conversion in the measured states or due to the quantization in matrices $H_i$ and $K_i$ of the region $\mathcal R_i$; and
    
  \item[(ii)] \emph{approximation in the computation of the affine function}: for any selected region $\mathcal R_i$, the affine function $v_{i}$ is evaluated using the quantized versions of $F_i$ and $G_i$.
\end{itemize}

We have to ensure that the sum of these two errors remain below the bound $\Delta$
used in the design of the robust explicit MPC:
\begin{equation}
  \max\{\|v_{i}-v_{j}\|,\,\forall i,j,\,\, i\neq j, \mathcal{R}_{i}\cap\mathcal{R}_{j}\neq\emptyset\} +  \max\{\mathit{err}(v_{i})_{p},\, i=1,2,\ldots,P\} \le \Delta.
  \label{eq:delta}
\end{equation}
%where $i,j$ are the indexes of two distinct regions $\mathcal{R}_{i}$ and $\mathcal{R}_{j}$, 
The first term is the error of incorrect region selection. The maximum is taken over all neighboring regions 
$\mathcal R_i,\mathcal R_j$ (two regions are neighboring if their intersection is non-empty).
The function norm $\|v_{i}-v_{j}\|$ is taken by maximizing over all possible values of the state $x$ %\RM{
in $\mathcal{R}_i \cap \mathcal{R}_j$. %}
The term $\mathit{err}(v_{i})_{p}$ in
the second part captures the approximation error in the computation of the affine function $v_{i}$ when a fixed precision $p$ is used.
%$\mathit{neighbor}(\mathcal{R}_{i},\mathcal{R}_{j})$
%states that two regions share at least a point, $v_{i}$ is the control action
%for controller $i$, and $err(v_{i})_{p}$ captures the approximation error for
%computing the control action $v_{i}$ in fixed precision $p$.

%\subsection{Incorrect Region Selection}
%
%The first part of the error in~\autoref{eq:delta} captures the error due to
%selecting of the incorrect region.
%This would happen since the matrices $H_i,K_i$ are stored in the hardware with fixed-point formats. In order to quantify the error, we define the expanded border $\bar{\mathcal B}_{ij}$ as the tube around the border between the regions $\mathcal{R}_i$ and $\mathcal{R}_j$:
%% \begin{equation*}
%% \bar{\mathcal R}_i := \bigcup_{\hat H_i,\hat K_i} \left\{x\in\mathbb R^n\,|\,\hat H_i x\le \hat K_i, \|H_i-\hat H_i\|\le \epsilon_f,\|K_i-\hat K_i\|\le \epsilon_f\right\}
%% \end{equation*}
%% for $i\in\{1,2,\ldots, P\}$, where $\epsilon_f$ is the maximum error of using fixed-point format instead of the precise values. The norm is also applied element-wise to the entries of the matrices. 
%
%\begin{equation*}
%\bar{\mathcal B}_{ij} := \left\{x\in\mathbb R^n\,|\, \| H_i x - K_i\| \le \varepsilon\,\, \text{ and }\,\, \| H_j x - K_j\| \le \varepsilon \right\},
%\end{equation*}
%where $\varepsilon$ captures the uncertainty in computing the correct region.
%%
%The width of the tube $\varepsilon$ is due to two sources of errors:
%analog-to-digital conversion $\varepsilon_{A/D}$ and the quantization of region
%bounds in memory $\varepsilon_{Q}$:
%\begin{equation}\label{eq:epsilontot}
%  \varepsilon=\varepsilon_{A/D}+\varepsilon_{Q}
%\end{equation}
%
%Analog conversion happens just before the controller receives the sensor input from the plant
%and is given by:
%\begin{equation*}
%\varepsilon_{A/D}=\frac{V_{cc}}{2^{r}-1}
%\end{equation*}
%where $V_{cc}$ is the reference voltage of the converter (e.g. typically 5V), $r$
%is the number of bits available to quantize the analog signal, and $2^{r}$ is
%the resolution of the converter.
%
%While $\varepsilon_{A/D}$ is intrinsic to the capabilities of the device,
%$\varepsilon_{Q}$ depends on the precision used to store the boundaries:
%\begin{equation}\label{eq:quantizationlines}
%  \varepsilon_{Q} \ge  \|(H_i - \hat{H}_i) \hat{x} + (K_i - \hat{K}_i)\|, \quad \forall \hat{x},\forall i,
%\end{equation}
%where $\hat{x}$ is the finite-precision value of $x$.
%%\eva{For which index is this evaluated, $i$, $j$ or both?}
%That is, $\varepsilon_{Q}$ bounds the distance between any hyperplane in infinite
%precision ($H$ and $K$ matrices), and its counter-part quantized by $p$ bits 
%($\hat{H}_{p}$ and $\hat{K}_{p}$).
%This second error can be tuned providing a trade-off between accuracy and
%memory storage required.
%
%% Note that $\mathcal R_i\subset \bar{\mathcal R}_i$. In other words, $\bar{\mathcal R}_i$ is the expanded version of $\mathcal R_i$.
%% Note that $\bar{\mathcal R}_i\cap \bar{\mathcal R}_j$ gives us the states where one of the two regions $\mathcal R_i, \mathcal R_i$ might be selected instead of the other one because of the fixed-precision implementation of the regions.   
%% $\bar{\mathcal R}_i$ is the expanded version of $\mathcal R_i$ that include all states in $\mathcal R_i$this definition expands the regions $\mathcal $
% %That is, with infinite-precision arithmetic
% Therefore, the first term in~\autoref{eq:delta} can be computed less conservatively by maximizing only over 
% the expanded borders:
% \begin{equation}
% \label{eq:maximization}
% \max_{x,i,j}\{\|F_ix+G_i-F_jx-G_j\|,\,x\in \bar{\mathcal B}_{ij}\}.
%% \max_{\forall i,j.\mathit{neighbor}(\mathcal{R}_{i},\mathcal{R}_{j})}&|F_{i}\statevar+G_{i} - (F_{j}\statevar+G_{j})|
% \end{equation}
 %%%%%%%%%%%%%%
 \subsection{Incorrect Region Selection}
 	The first part of the error in~\autoref{eq:delta} captures the error due to
 	selecting of the incorrect region.
 	This would happen since the matrices $H_i,K_i$ are stored in the hardware with fixed-point formats. In order to quantify the error, we define the expanded border $\bar{\mathcal B}_{ij}$ as the tube around the border between the regions $\mathcal{R}_i$ and $\mathcal{R}_j$:
 	\begin{equation*}
 	\bar{\mathcal B}_{ij} := \left\{x\in\mathbb R^n\,|\, \| H_i x - K_i\| \le \varepsilon\,\, \text{ and }\,\, \| H_j x - K_j\| \le \varepsilon \right\},
 	\end{equation*}
 	where $\varepsilon$ captures the uncertainty in computing the correct region.
 	%
 	The width of the tube $\varepsilon$ is due to two sources of errors:
 	\begin{itemize}
 		\item analog-to-digital conversion $\varepsilon_{A/D}$: 
		the error introduced by using the quantized output of the analog-to-digital converter $\hat x$ instead of the actual state $x$. 
		We assume $\|x - \hat x\|\le \varepsilon_{A/D}$.
 		\item quantization of region bounds in memory $\varepsilon_{Q}$: the error introduced by 
		using the quantized versions $\hat H_i$, $\hat K_i$ of $H_i$, $K_i$ with $p$ bits of precision. 
		This is related to the boundaries of the regions.
 		%\item using $\hat F_i,\hat G_i$ which are the quantized versions of $F_i,G_i$ with $p$ bits precision. This is related to the affine functions.
 	\end{itemize}
 	Note that the error resulting from using the quantized versions of $F_i,G_i$ will be discussed in \autoref{subsec:app_cont_err}.
 	We define the fixed point realization of the controller in \autoref{eq:affine_map} as
 	 	\begin{equation}
 	 	\label{eq:affine_map_hat}
 	 	\hat\kappa(\hat x_k)=
 	 	\begin{cases}
 	 	\hat F_1\hat x_k+\hat G_1 & \text{if $\hat x_k\in \mathcal{\hat R}_1$}\\
 	 	\hat F_2\hat x_k+\hat G_2 & \text{if $\hat x_k\in \mathcal{\hat R}_2$}\\
 	 	\vdots\\
 	 	\hat F_P x_k+\hat G_P & \text{if $ \hat x_k\in \mathcal{\hat R}_P$}.
 	 	\end{cases} 
 	 	\end{equation}
 	 	where $\mathcal{\hat R}_i$ is a polyhedral region determined by a set of linear inequalities 
$\mathcal{\hat R}_i= \{ \hat x\in\mathcal X\mid \hat H_i\hat x\leq \hat K_i\}$. 
Let us define the sets $\mathcal H := \{H_i,K_i\mid i=1,2,\ldots, P\}$ and $\mathcal F:=\{F_i,G_i \mid i=1,2,\ldots, P\}$. 
Similarly, we define $\hat{\mathcal H}:= \{\hat H_i,\hat K_i\mid i=1,2,\ldots, P\}$ and $\hat{\mathcal F}:=\{\hat F_i,\hat G_i\mid i=1,2,\ldots, P\}$. 
Using the triangle inequality we have:
 	 	\begin{align*}
 	 	\|\kappa(x)-\hat \kappa(\hat x)
 	 	\|\le&\|\kappa(\mathcal H,\mathcal F,x)-\kappa(\hat{\mathcal H},\mathcal F,\hat x)\| +\|\kappa(\hat{\mathcal H},\mathcal F,\hat x)-\kappa(\hat{\mathcal H},\hat{\mathcal F},\hat x)\|.
 	 	\end{align*}
 	 	where $\kappa(\mathcal H^*,\mathcal F^*,x^*)$ denotes the controller defined over the sets $\mathcal F^*$, $\mathcal H^*$ and the state $x^*$. 
	The second term on the right corresponds to the control approximation error and will be discussed in \autoref{subsec:app_cont_err}.
 	 	The first term can be further decomposed as
 	 	\begin{align*}
 	 	\|\kappa(\mathcal H,&\mathcal F,x)-\kappa(\hat{\mathcal H},\mathcal F,\hat x)\|\\
 	 	&\le \|\kappa(\mathcal H,\mathcal F,x)-\kappa(\mathcal H,\mathcal F,\hat x)\|+
 	 	\|\kappa(\mathcal H,\mathcal F,\hat x) - \kappa(\hat{\mathcal H},\mathcal F,\hat x)\|\\
 	 	&\le \max_i\{\|F_i\|_2\}\|x-\hat x\| + \varepsilon_Q\\
 	 	& \le \max_i\{\|F_i\|_2\}\varepsilon_{A/D}+ \varepsilon_Q.
 	 	\end{align*}
 	 	Therefore, we can compute the tube width $\varepsilon$ as:
 	 	\begin{equation}\label{eq:epsilontot}
 	 	\varepsilon=\max_i \{||F_i||_2\}\varepsilon_{A/D}+\varepsilon_{Q}.
 	 	\end{equation}
 	
% 	\Mahmoud{We define the fixed point realization of the controller in \autoref{eq:affine_map} as:
% 	\begin{equation}
% 	\label{eq:affine_map_hat}
% 	\hat\kappa(\hat x_k)=
% 	\begin{cases}
% 	\hat F_1\hat x_k+\hat G_1 & \text{if $\hat x_k\in \mathcal{\hat R}_1$}\\
% 	\hat F_2\hat x_k+\hat G_2 & \text{if $\hat x_k\in \mathcal{\hat R}_2$}\\
% 	\vdots\\
% 	\hat F_P x_k+\hat G_P & \text{if $ \hat x_k\in \mathcal{\hat R}_P$}
% 	\end{cases} 
% 	\end{equation}
% 	where $\hat x_k$ denotes the output of the analog-to-digital converter corresponding to the input $x_k$. Further, $\hat F_i, \hat G_i$ denote the fixed point representations corresponding to $F_i, G_i$ and $\mathcal{\hat R}_i$ is a polyhedral region determined by a set of linear inequalities $\mathcal{\hat R}_i= \{ \hat x\in\mathcal X\,|\, \hat H_i\hat x\leq \hat K_i\}$.}
%
%	\Mahmoud{Let us define the sets $\mathcal H := \{H_i,K_i,i=1,2,\ldots, P\}$ and $\mathcal F:=\{F_i,G_i,i=1,2,\ldots, P\}$. Similarly, we define $\hat{\mathcal H}:= \{\hat H_i,\hat K_i,i=1,2,\ldots, P\}$ and $\hat{\mathcal F}:=\{\hat F_i,\hat G_i,i=1,2,\ldots, P\}$, where $\hat F_i$, $\hat G_i$, $\hat H_i$ and $\hat K_i$ denote the fixed point representations corresponding to $F_i$, $G_i$, $H_i$ and $K_i$, respectively. }
%
% 	\begin{equation}\label{eq:epsilontot1}
% 	\varepsilon=\varepsilon_{A/D}+\varepsilon_{Q}
% 	\end{equation}
 	%
 	%
 	Analog conversion happens just before the controller receives the sensor input from the plant
 	and is given by:
 	\begin{equation*}
 	\varepsilon_{A/D}=\frac{V_{cc}}{2^{r}-1}
 	\end{equation*}
 	where $V_{cc}$ is the reference voltage of the converter (e.g. typically 5V), $r$
 	is the number of bits available to quantize the analog signal, and $2^{r}$ is
 	the resolution of the converter.\\
 	While $\varepsilon_{A/D}$ is intrinsic to the capabilities of the device,
 	$\varepsilon_{Q}$ depends on the precision used to store the boundaries:
 	\begin{equation}\label{eq:quantizationlines}
 	\varepsilon_{Q} \ge  \|(H_i - \hat{H}_i) \hat{x} + (K_i - \hat{K}_i)\|, \quad \forall \hat{x},\forall i,
 	\end{equation}
 	where $\hat{x}$ is the finite-precision value of $x$.
 	%\eva{For which index is this evaluated, $i$, $j$ or both?}
 	That is, $\varepsilon_{Q}$ bounds the distance between any hyperplane in infinite
 	precision ($H$ and $K$ matrices), and its counter-part quantized by $p$ bits 
 	($\hat{H}$ and $\hat{K}$).
 	This second error can be tuned providing a trade-off between accuracy and
 	memory storage required.
 	Therefore, the first term in~\autoref{eq:delta} can be computed less conservatively by maximizing only over 
 	the expanded borders:
 	\begin{equation}
 	\label{eq:maximization}
 	\max_{x,i,j}\{\|F_ix+G_i-F_jx-G_j\|,\,x\in \bar{\mathcal B}_{ij}\}.
 	% \max_{\forall i,j.\mathit{neighbor}(\mathcal{R}_{i},\mathcal{R}_{j})}&|F_{i}\statevar+G_{i} - (F_{j}\statevar+G_{j})|
 	\end{equation}
 
 %\Mahmoudd{ 
 %\begin{remark}
 %	Our formulation is general enough to take the effect of measurement/process noise into account. More specifically, $\Delta$ in $\mathcal{W}_{\Delta}$ can in general give upper-bound over the sum of uncertainties with different sources. However, this is not subject of study of the current paper. Moreover, to cover nonlinear systems, one approach is to linearize them around an appropriately selected equilibrium point of the system and to model the differences as a bounded disturbance as in \autoref{eq:RMPC_prob}. Taking the upper bound over nonlinearities into account will result in enlarging $\Delta$ which characterizes $\mathcal{W}_{\Delta}$. For reasonable values of $\Delta$, in principle RMPC design should work successfully. Further, it should be noticed that the rest of analysis (over MATLAB and Daisy) do not rely on the LTI property of the under study system and could be adjusted for other families of controllers. However, such analysis are beyond the scope of this paper as (perturbed) LTI systems are considered as an important class of dynamical systems.
 %	\end{remark}}

%and in the absence of any uncertainty from hardware measurements we would choose
%control action $v_{i}$, but due to uncertainties we actually choose control action $v_{j}$:
%\begin{align} \label{eq:maximization}
 % \max_{\forall i,j.\mathit{neighbor}(\mathcal{R}_{i},\mathcal{R}_{j})}|v_{i}-v_{j}|&= \\
 % \max_{\forall i,j.\mathit{neighbor}(\mathcal{R}_{i},\mathcal{R}_{j})}&|F_{i}\statevar+G_{i} - (F_{j}\statevar+G_{j})|\nonumber
%\end{align}

%Because of the linearity of the function $v_{i}-v_{j}$, and because of the
%convexity of the regions $i$ and $j$, it is enough to evaluate function
%(\ref{eq:maximization}) at the corner points of the \texttt{tube}, instead of
%solving a maximization problem.

%A naive computation of this error would consider all possible values of $x_k$.
%This would lead to a gross over-approximation, however, since the controller
%will choose a wrong region only in a relative narrow neighborhood, or
%\emph{tube}, around the boundary between two regions $R_i$ and $R_j$.

%The border between two regions $\mathcal{R}_{i}$ and $\mathcal{R}_{j}$ is defined by 
%their corresponding boundaries:
%\begin{equation}
%\mathit{border}_{i,j} :=(H_i \statevar - K_i ) - (H_j \statevar - K_j)
%\end{equation}
%for appropriate matching borders $H_i, K_i$ and $H_j, K_j$.

%In~\autoref{eq:maximization}, we thus constrain $\statevar$ to be within an appropriate tube:
%\begin{equation}\label{eq:tube}
%|\mathit{border}_{i,j}| \le \varepsilon
%\end{equation}
%where $\varepsilon$ captures the uncertainty in computing the
%correct region and thus the width of the tube.
%

\begin{comment}
We should also include the error in 
The width of the tube $\varepsilon$ is due to two sources of errors:
analog-to-digital conversion $\varepsilon_{A/D}$ and the quantization of region
bounds in memory $\varepsilon_{Q}$:
\begin{equation}\label{eq:epsilontot}
  \varepsilon=\varepsilon_{A/D}+\varepsilon_{Q}
\end{equation}

Analog conversion happens just before the controller receives the sensor input from the plant
and is given by:
\begin{equation*}
\varepsilon_{A/D}=\frac{V_{cc}}{2^{r}-1}
\end{equation*}
where $V_{cc}$ is the reference voltage of the converter (e.g. typically 5V), $r$
is the number of bits available to quantize the analog signal, and $2^{r}$ is
the resolution of the converter.

While $\varepsilon_{A/D}$ is intrinsic to the capabilities of the device,
$\varepsilon_{Q}$ depends on the precision used to store the boundaries:
\begin{equation}\label{eq:quantizationlines}
  \varepsilon_{Q} \ge  |(H_i - \hat{H}_i) \qstatevar + (K_i - \hat{K}_i)|, \forall  \qstatevar
\end{equation}
\eva{For which index is this evaluated, $i$, $j$ or both?}
That is, $\varepsilon_{Q}$ bounds the distance between any hyperplane in infinite
precision (H and K), and its counter-part quantized in $p$ bits precision
($\hat{H}_{p}$ and $\hat{K}_{p}$).
This second error can be tuned providing a trade-off between accuracy and
memory storage required.
\end{comment}


\subsection{Approximate Control Output}
\label{subsec:app_cont_err}

% We should also include the error due to
% analog-to-digital conversion $\varepsilon_{A/D}$.
% Analog to digital conversion happens just before the controller receives the measured state from sensor
% and is given by:
% \begin{equation*}
% \varepsilon_{A/D}=\frac{V_{cc}}{2^{r}-1}
% \end{equation*}
% where $V_{cc}$ is the reference voltage of the converter (e.g. typically 5V), $r$
% is the number of bits available to quantize the analog signal, and $2^{r}$ is
% the resolution of the converter. The associated error in the output of the controller is $\varepsilon_{A/D}\max_i\{\|K+F_i\|\}$.

Once a quantized state $\hat x$ is given and a region $\mathcal R_i$ is chosen, computing $v_{i}$ itself introduces
imprecision, because, $v_{i}$ needs to be evaluated in finite-precision arithmetic:
\begin{equation}\label{eq:fperror}
  err(v_{i})_{p} \ge  | (F_i - \hat{F}_{i}) \statevar + ( G_i - \hat{G}_{i} ) |,\quad \forall \statevar\in \mathcal{R}_i\cup\bar{\mathcal B}_{ij},\,\,\forall j,
\end{equation}
where $\hat{F}$ and $\hat{G}$ represent the quantized values (in $p$ bits) for
the infinite precision values $F$ and $G$.

\autoref{eq:fperror} is evaluated for all \statevarmath that are inside the
region $\mathcal{R}_i$, together with all the values in the tube surrounding
region $\mathcal{R}_i$ (union of $\bar{\mathcal B}_{ij}$ for all $j$).
In this way we compute the error also for those points that belong to a neighbor
of $\mathcal{R}_i$, but because of finite-precision errors they are erroneously
mapped to control action $v_{i}$.

\subsection{Implementation}

The incorrect region error (\autoref{eq:maximization}) is computed with Matlab. Since $v_{i}-v_{j}$ is also affine, and because we defined the tube as a convex region 
surrounding the corresponding hyperplane, it suffices
to evaluate the function only at the corner points of the tube, and keep the
result with the maximal magnitude. 
To evaluate the incorrect region selection error across
the corner points, we need to first locate the corner points as well as all the
regions which share those corner points. 
Each region $R_i$ is represented by a set of constraints. We first extract the
set of vertices of $R_i$ using the open source Matlab library
$\mathit{lcon2vert}$~\cite{lcon2vertMatlab}.
For each computed vertex $v_i$, we compute a $n$-dimensional
hypercube with the edge length of $2 \varepsilon$. 
Each of the $2^n$ vertices of this hypercube is counted as a corner point, on which
we evaluate $\|u_i - u_j\|$. 

In order to find out which regions share a vertex $v_i$, we implemented two approaches.
The first approach determines the set of neighboring regions via an exhaustive
search over the set of vertices. However, we observed that this algorithm only
scales to small numbers of regions.
Our second approach works on the observation that all the regions $R_j$s 
having $v_i$ as their vertex can be identified if at least $n$ of their hyperplanes cross $v_i$. 

% In brief, we go
% through these steps: (i) for each region, the set of vertices are computed; (ii)
% for the vertex $v_i$, the set of all regions $\mathcal R_{ij}$ having $v_i$ as
% their own vertex are found; (iii) for the vertex $v_i$, the set of corner points
% $v_{ik}$ are computed which form a hypercube centering at $v_i$; (iv) for every
% corner point $c_k=v_{ik}$ and for every pair $(\mathcal R_{ij1},\mathcal
% R_{ij_2})$, the corresponding corner error $|v_{j1}-v_{j2}|$ is computed; (v)
% finally, we pick the greatest corner error.

% \eva{This needs more details. Which function(s) and algorithm from Matlab are used?}
% \eva{How do you determine which regions are neighbors? resp. which borders are matching?}

The error terms $\varepsilon_Q$ and $err(v_{i})_{p}$ are computed by Daisy. For this we encode
the expressions in~\autoref{eq:quantizationlines} and \autoref{eq:fperror}
respectively as straight-line arithmetic expressions and specify the constraints
on the domain of $\statevar$ in the precondition.
Daisy performs a dataflow analysis to determine the finite-precision roundoff
errors. 
% This error computation differs from the one employed by
% \citet{imperialrmpc} which phrases the roundoff error computation as a (relaxed)
% mixed integer programming problem.

While our actual synthesis algorithm (\autoref{sec:Controller_Synthesis}) does
not compute the errors $\varepsilon_Q$ and $err(v_{i})_{p}$ explicitly, the
error verification is used internally by Daisy to determine a suitable precision
$p$ and can also be called explicitly without the precision optimization. 

Note that we use MATLAB and Daisy solely for offline computations during the compilation of the controller.
At runtime, there is no additional cost.
% The output of our algorithm contains (almost) all the information required for implementation of the verified controller over embedded systems. 
% Therefore, the same savings can be expected when the controller is implemented on an actual embedded system.

%\RM{what about the following commented-out comment of Sadegh?}
\begin{comment}
\textcolor{red}{Sadegh: This is long comment on the content of this section. I cannot figure out how this line of reasoning is mapped to the implementation. We can discard my comment given that we are close to the deadline.}

\Sadegh{
I don't agree that we should add $\varepsilon_{A/D}$ and $\varepsilon_Q$ together. I understand that the implementation is done according to this, but I think we need to multiply $\varepsilon_{A/D}$ by the maximum norm of the coefficients $F_i$ in the controller. There are three approximations:
\begin{itemize}
\item using the quantized measured state $\hat x$ instead of the actual state $x$. We assume $\|x - \hat x\|\le \varepsilon_{A/D}$.
\item using $\hat H_i,\hat K_i$ which are the quantized versions of $H_i,K_i$ with $p$ bits precision. This is related to the boundaries of the regions.
\item using $\hat F_i,\hat G_i$ which are the quantized versions of $F_i,G_i$ with $p$ bits precision. This is related to the affine functions.
\end{itemize}
Let me define the sets $\mathcal H := \{H_i,K_i,i=1,2,\ldots, P\}$ and $\mathcal F:=\{F_i,G_i,i=1,2,\ldots, P\}$. Similarly, we define $\hat{\mathcal H}$ and $\hat{\mathcal F}$.
The controller (which is a piecewise affine function) can be written as the parametric function $\kappa(\mathcal H,\mathcal F,x)$. Our main goal is to make sure that
$$\|\kappa(\mathcal H,\mathcal F,x)-\kappa(\hat{\mathcal H},\hat{\mathcal F},\hat x)\|\le \Delta,\quad \forall x\in\mathcal X_{\mathsf s}.$$
We use tirangle these inequality:
\begin{align*}
\|\kappa(\mathcal H,\mathcal F,x)-\kappa(\hat{\mathcal H},\hat{\mathcal F},\hat x)
\|\le&\|\kappa(\mathcal H,\mathcal F,x)-\kappa(\hat{\mathcal H},\mathcal F,\hat x)\|\\
+&\|\kappa(\hat{\mathcal H},\mathcal F,\hat x)-\kappa(\hat{\mathcal H},\hat{\mathcal F},\hat x)\|.
\end{align*}
The second term is exactly what we have in section 4.2 (error in the evaluation of the affine function).
The first term can be further decomposed as
\begin{align*}
\|\kappa(\mathcal H,&\mathcal F,x)-\kappa(\hat{\mathcal H},\mathcal F,\hat x)\|\\
&\le \|\kappa(\mathcal H,\mathcal F,x)-\kappa(\mathcal H,\mathcal F,\hat x)\|+
 \|\kappa(\mathcal H,\mathcal F,\hat x) - \kappa(\hat{\mathcal H},\mathcal F,\hat x)\|\\
&\le \max_i\{\|F_i\|_2\}\|x-\hat x\| + \varepsilon_Q\\
& \le \max_i\{\|F_i\|_2\}\varepsilon_{A/D}+ \varepsilon_Q.
\end{align*}
The error $\varepsilon_{A/D}$ shows itself in the output of the controller by being amplified with the Lipschitz constant of the function which is $\max_i\{\|F_i\|_2\}$. 
As far as I can tell, $\varepsilon_{A/D}$ doesn't have anything to do with $\varepsilon_Q$. The computation of $\varepsilon_Q$ should be only with respect to the use of $\hat{\mathcal H}$ instead of $\mathcal H$ in the evaluation of constraints for the same value $\hat x$.
}
\end{comment}
% The approximation error and the precision tuning for both borders and active
% functions are computed in Daisy. $\varepsilon_{Q}$ is given in input to the
% analysis. After we compute the incorrect region in MATLAB we obtain the value
% for max error $err(v_{i})$ from (8). Then we give the errors and the vectors F,G
% and H,K in input to Daisy. We used Daisy as a verification tool: we provide in
% input the expression we want to quantize (e.g. $\mathcal{R}_{i}$) together with
% the error bound we can tolerate (e.g. $\varepsilon_{Q}$), and Daisy returns a
% precision configuration (uniform or mixed) such that the input error is
% satisfied. The way it finds the right configuration for uniform precision is the
% following: it starts by checking whether the input expression, quantized in
% unary uniform precision (1bit), introduces an error bounded by the input error.
% If this is not the case, Daisy increases the precision format by 1 bit and check
% whether the error now is satisfied. This unary increment runs inside a loop that
% terminates when the first valid format is matched. This uniform word-length is
% going to be the baseline for the mixed-precision tuning phase. The
% mixed-precision algorithm keeps a list of variables to quantize, and collects
% different candidate configurations that satisfy the input error. It returns the
% best configuration based on the evaluation of a quality function.


